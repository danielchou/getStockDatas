{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U16 financial features analysis\n",
    "\n",
    "## 拿取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab.data import Data\n",
    "data = Data()\n",
    "\n",
    "twii = data.get('發行量加權股價指數')\n",
    "twii = twii['台股指數']\n",
    "twii = twii[(twii.index.minute % 15 == 0)  & (twii.index.second == 0)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "twii.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 製作features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sma = talib.SMA(twii, timeperiod=120)\n",
    "wma = talib.WMA(twii, timeperiod=120)\n",
    "mom = talib.MOM(twii, timeperiod=120)\n",
    "k, d = talib.STOCH  (twii, twii, twii, fastk_period=120, slowk_period=60, slowd_period=60)\n",
    "k2, d2 = talib.STOCH(twii, twii, twii, fastk_period=240, slowk_period=120, slowd_period=120)\n",
    "k3, d3 = talib.STOCH(twii, twii, twii, fastk_period=360, slowk_period=180, slowd_period=180)\n",
    "k4, d4 = talib.STOCH(twii, twii, twii, fastk_period=480, slowk_period=240, slowd_period=240)\n",
    "k5, d5 = talib.STOCH(twii, twii, twii, fastk_period=640, slowk_period=320, slowd_period=320)\n",
    "k6, d6 = talib.STOCH(twii, twii, twii, fastk_period=720, slowk_period=360, slowd_period=360)\n",
    "k7, d7 = talib.STOCH(twii, twii, twii, fastk_period=840, slowk_period=420, slowd_period=420)\n",
    "k8, d8 = talib.STOCH(twii, twii, twii, fastk_period=960, slowk_period=480, slowd_period=480)\n",
    "\n",
    "rsi = talib.RSI (twii, timeperiod=120)\n",
    "rsi2 = talib.RSI(twii, timeperiod=240)\n",
    "rsi3 = talib.RSI(twii, timeperiod=480)\n",
    "rsi4 = talib.RSI(twii, timeperiod=640)\n",
    "rsi5 = talib.RSI(twii, timeperiod=720)\n",
    "rsi6 = talib.RSI(twii, timeperiod=840)\n",
    "\n",
    "macd1, macd2, macd3 = talib.MACD(twii, fastperiod=120, slowperiod=60, signalperiod=60)\n",
    "willr = talib.WILLR(twii, twii, twii, timeperiod=120)\n",
    "cci = talib.CCI(twii, twii, twii, timeperiod=120)\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'RSIb': rsi / 50,\n",
    "    'RSIb2': rsi2 / 50,\n",
    "    'RSIb3': rsi3 / 50,\n",
    "    'RSIb4': rsi4 / 50,\n",
    "    'RSIb5': rsi5 / 50,\n",
    "    'RSIb6': rsi6 / 50,\n",
    "    'KDb': k - d,\n",
    "    'KDb2': k2 - d2,\n",
    "    'KDb3': k3 - d3,\n",
    "    'KDb4': k4 - d4,\n",
    "    'KDb5': k5 - d5,\n",
    "    'KDb6': k6 - d6,\n",
    "    'KDb7': k7 - d7,\n",
    "    'KDb8': k8 - d8,\n",
    "    \n",
    "    'a5':   (twii.rolling(5).mean()   / twii),\n",
    "    'a10':  (twii.rolling(10).mean()  / twii),\n",
    "    'a20':  (twii.rolling(20).mean()  / twii),\n",
    "    'a40':  (twii.rolling(40).mean()  / twii),\n",
    "    'a80':  (twii.rolling(80).mean()  / twii),\n",
    "    'a160': (twii.rolling(160).mean() / twii),\n",
    "    'a320': (twii.rolling(320).mean() / twii),\n",
    "    'a640': (twii.rolling(640).mean() / twii),\n",
    "    'a720': (twii.rolling(720).mean() / twii),\n",
    "    'a840': (twii.rolling(840).mean() / twii),\n",
    "    'a960': (twii.rolling(960).mean() / twii),\n",
    "    'a1024':(twii.rolling(1024).mean() / twii),\n",
    "    'b1': twii/twii.shift(50),\n",
    "    'b2': twii/twii.shift(100),\n",
    "    'b3': twii/twii.shift(150),\n",
    "    'b4': twii/twii.shift(200),\n",
    "    'b5': twii/twii.shift(250),\n",
    "    'b6': twii/twii.shift(300),\n",
    "    'b7': twii/twii.shift(350),\n",
    "    'LINEARREG_SLOPE0': talib.LINEARREG_SLOPE(twii, 60),\n",
    "    'LINEARREG_SLOPE1': talib.LINEARREG_SLOPE(twii, 120),\n",
    "\n",
    "    'ADXR0': talib.ADXR(twii, twii, twii, 60),\n",
    "    'ADXR1': talib.ADXR(twii, twii, twii, 120),\n",
    "    'ADXR2': talib.ADXR(twii, twii, twii, 240),\n",
    "    'ADXR3': talib.ADXR(twii, twii, twii, 360),\n",
    "    'ADXR4': talib.ADXR(twii, twii, twii, 480),\n",
    "    'ADXR5': talib.ADXR(twii, twii, twii, 640),\n",
    "\n",
    "    'return': twii.shift(-10) > twii,\n",
    "})\n",
    "\n",
    "feature_names = list(dataset.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "dataset_train = dataset[:'2015']\n",
    "dataset_test = dataset['2016':]\n",
    "\n",
    "train = dataset_train[feature_names], dataset_train['return']\n",
    "test = dataset_test[feature_names], dataset_test['return']\n",
    "\n",
    "gbm = lgb.LGBMClassifier(n_estimators=1000, random_state=5, learning_rate=0.05)\n",
    "gbm.fit(*train)\n",
    "gbm.score(*test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試哪些feature重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(gbm.feature_importances_,feature_names)), columns=['Value','Feature'])\n",
    "feature_imp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回測一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ey = gbm.predict_proba(dataset[feature_names])\n",
    "ey = pd.Series(ey.swapaxes(0,1)[1], index=dataset.index)\n",
    "\n",
    "eq = twii[dataset.index]\n",
    "gain = ((eq.shift(-1) - eq))\n",
    "\n",
    "signal = (ey > ey.quantile(0.7)).rolling(10).sum() > 0\n",
    "eq = (gain[signal]['2016':]).cumsum()\n",
    "eq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手續費+滑價"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal['2016'].astype(int).diff().abs().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U17 Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(dataset['return']['2016':], ey['2016':])\n",
    "\n",
    "pd.DataFrame({\n",
    "    'precisions':precisions[:-1],\n",
    "    'recalls':recalls[:-1],\n",
    "}, index=thresholds).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(dataset['return']['2016':], ey['2016':])\n",
    "\n",
    "print(fpr.shape)\n",
    "print(tpr.shape)\n",
    "print(thresholds.shape)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 eli5 察看機器學習如何做決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import _scorer\n",
    "sys.modules['sklearn.metrics.scorer'] = _scorer\n",
    "\n",
    "from sklearn.feature_selection import _base\n",
    "sys.modules['sklearn.feature_selection.base'] = _base\n",
    "\n",
    "import eli5\n",
    "eli5.explain_prediction_lightgbm(gbm, dataset[feature_names].iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Skater來察看機器學習如何做實驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from skater.core.explanations import Interpretation\n",
    "from skater.model import InMemoryModel\n",
    "# 新版的skater 不支援 dataset 中有 nan，必須先將有 nan 的 rows 移除喔！\n",
    "dataset_train_dropna = dataset_train.dropna(how='any')\n",
    "\n",
    "\n",
    "interpreter = Interpretation(training_data=dataset_train_dropna[feature_names].values[:1000],\n",
    "                             feature_names=feature_names, training_labels=dataset_train_dropna['return'].values[:1000])\n",
    "im_model = InMemoryModel(lambda x: gbm.predict_proba(x), examples=train[0],\n",
    "                         target_names=['down', 'rise'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plots = interpreter.feature_importance.plot_feature_importance(im_model, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 挑幾項出來看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = interpreter.partial_dependence.plot_partial_dependence([('ADXR3', 'KDb2')], im_model, n_jobs=1, grid_resolution=10, \n",
    "                                                           grid_range=(0,1), n_samples=1000,\n",
    "                                                           with_variance=False, figsize = (6, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分析為何判定會漲？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "exp = LimeTabularExplainer(dataset_test[feature_names].values, feature_names=feature_names)\n",
    "\n",
    "doc_num = 0\n",
    "exp.explain_instance(dataset_test[feature_names].iloc[doc_num], gbm.predict_proba).show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_num = 0\n",
    "print('Actual Label:', dataset_test['return'].iloc[doc_num])\n",
    "print('Predicted Label:', gbm.predict_proba(dataset_test[feature_names])[0])\n",
    "exp.explain_instance(dataset_test[feature_names].iloc[doc_num], gbm.predict_proba).show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP 分析package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "X = dataset_test[feature_names][::100]\n",
    "shap_values = explainer.shap_values(X)\n",
    "print('Expected Value:', explainer.expected_value)\n",
    "pd.DataFrame(shap_values[1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "doc_id = 100\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[1], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[1][0], feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 傳統策略研發"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(k1, k2, plot=False):\n",
    "    \n",
    "    k2, d2 = talib.STOCH(twii, twii, twii, fastk_period=k1, slowk_period=k2, slowd_period=k2/2)\n",
    "    buy = k2 > d2\n",
    "    sell = k2 < d2\n",
    "\n",
    "    hold = pd.Series(np.nan, index=twii.index)\n",
    "    hold[buy] = 1\n",
    "    hold[sell] = -1\n",
    "    hold.ffill(inplace=True)\n",
    "\n",
    "    if (hold == 1).sum() == 0:\n",
    "        return 1\n",
    "    \n",
    "    returns = twii.shift(-1) - twii\n",
    "    \n",
    "    if plot:\n",
    "        \n",
    "        returns[hold == 1][:'2015'].cumsum().plot()\n",
    "    \n",
    "    return returns[hold == 1][:'2015'].cumsum().iloc[-1]\n",
    "   \n",
    "\n",
    "maxr = 0\n",
    "for k1 in range(40, 100, 1):\n",
    "    for k2 in range(40, 100, 1):\n",
    "        if k1 <= k2:\n",
    "            continue\n",
    "        r = backtest(k1, k2)\n",
    "        if r > maxr:\n",
    "            print(r, k1, k2)\n",
    "            maxr = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest(88, 56, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finlab_test",
   "language": "python",
   "name": "finlab_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神經網路實做"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拿取加權指數資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab.data import Data\n",
    "\n",
    "data = Data()\n",
    "twii = data.get(\"發行量加權股價指數\")\n",
    "\n",
    "twii = twii['台股指數'].resample(\"15T\").first().dropna()\n",
    "twii.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 製作features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sma = talib.SMA(twii, timeperiod=120)\n",
    "wma = talib.WMA(twii, timeperiod=120)\n",
    "mom = talib.MOM(twii, timeperiod=120)\n",
    "k, d = talib.STOCH  (twii, twii, twii, fastk_period=120, slowk_period=60, slowd_period=60)\n",
    "k2, d2 = talib.STOCH(twii, twii, twii, fastk_period=240, slowk_period=120, slowd_period=120)\n",
    "k3, d3 = talib.STOCH(twii, twii, twii, fastk_period=360, slowk_period=180, slowd_period=180)\n",
    "k4, d4 = talib.STOCH(twii, twii, twii, fastk_period=480, slowk_period=240, slowd_period=240)\n",
    "k5, d5 = talib.STOCH(twii, twii, twii, fastk_period=640, slowk_period=320, slowd_period=320)\n",
    "k6, d6 = talib.STOCH(twii, twii, twii, fastk_period=720, slowk_period=360, slowd_period=360)\n",
    "k7, d7 = talib.STOCH(twii, twii, twii, fastk_period=840, slowk_period=420, slowd_period=420)\n",
    "k8, d8 = talib.STOCH(twii, twii, twii, fastk_period=960, slowk_period=480, slowd_period=480)\n",
    "\n",
    "rsi = talib.RSI (twii, timeperiod=120)\n",
    "rsi2 = talib.RSI(twii, timeperiod=240)\n",
    "rsi3 = talib.RSI(twii, timeperiod=480)\n",
    "rsi4 = talib.RSI(twii, timeperiod=640)\n",
    "rsi5 = talib.RSI(twii, timeperiod=720)\n",
    "rsi6 = talib.RSI(twii, timeperiod=840)\n",
    "\n",
    "macd1, macd2, macd3 = talib.MACD(twii, fastperiod=120, slowperiod=60, signalperiod=60)\n",
    "willr = talib.WILLR(twii, twii, twii, timeperiod=120)\n",
    "cci = talib.CCI(twii, twii, twii, timeperiod=120)\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'RSIb': rsi / 50,\n",
    "    'RSIb2': rsi2 / 50,\n",
    "    'RSIb3': rsi3 / 50,\n",
    "    'RSIb4': rsi4 / 50,\n",
    "    'RSIb5': rsi5 / 50,\n",
    "    'RSIb6': rsi6 / 50,\n",
    "    'MOMb': mom - 0,\n",
    "    'KDb': k - d,\n",
    "    'KDb2': k2 - d2,\n",
    "    'KDb3': k3 - d3,\n",
    "    'KDb4': k4 - d4,\n",
    "    'KDb5': k5 - d5,\n",
    "    'KDb6': k6 - d6,\n",
    "    'KDb7': k7 - d7,\n",
    "    'KDb8': k8 - d8,\n",
    "    \n",
    "    'a5':   (twii.rolling(5).mean()   / twii),\n",
    "    'a10':  (twii.rolling(10).mean()  / twii),\n",
    "    'a20':  (twii.rolling(20).mean()  / twii),\n",
    "    'a40':  (twii.rolling(40).mean()  / twii),\n",
    "    'a80':  (twii.rolling(80).mean()  / twii),\n",
    "    'a160': (twii.rolling(160).mean() / twii),\n",
    "    'a320': (twii.rolling(320).mean() / twii),\n",
    "    'a640': (twii.rolling(640).mean() / twii),\n",
    "    'a720': (twii.rolling(720).mean() / twii),\n",
    "    'a840': (twii.rolling(840).mean() / twii),\n",
    "    'a960': (twii.rolling(960).mean() / twii),\n",
    "    'a1024':(twii.rolling(1024).mean() / twii),\n",
    "    'b1': twii/twii.shift(50),\n",
    "    'b2': twii/twii.shift(100),\n",
    "    'b3': twii/twii.shift(150),\n",
    "    'b4': twii/twii.shift(200),\n",
    "    'b5': twii/twii.shift(250),\n",
    "    'b6': twii/twii.shift(300),\n",
    "    'b7': twii/twii.shift(350),\n",
    "    'LINEARREG_SLOPE0': talib.LINEARREG_SLOPE(twii, 60),\n",
    "    'LINEARREG_SLOPE1': talib.LINEARREG_SLOPE(twii, 120),\n",
    "\n",
    "    'ADXR0': talib.ADXR(twii, twii, twii, 60),\n",
    "    'ADXR1': talib.ADXR(twii, twii, twii, 120),\n",
    "    'ADXR2': talib.ADXR(twii, twii, twii, 240),\n",
    "    'ADXR3': talib.ADXR(twii, twii, twii, 360),\n",
    "    'ADXR4': talib.ADXR(twii, twii, twii, 480),\n",
    "    'ADXR5': talib.ADXR(twii, twii, twii, 640),\n",
    "\n",
    "    'return': twii.shift(-10) / twii,\n",
    "})\n",
    "\n",
    "feature_names = list(dataset.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 簡單處理一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before dropping NaN\", dataset.shape)\n",
    "dataset = dataset.dropna()\n",
    "print(\"after dropping NaN\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "dataset_train = dataset[:'2015']\n",
    "\n",
    "gbm = lgb.LGBMClassifier(n_estimators=100, random_state=5, learning_rate=0.01)\n",
    "\n",
    "gbm.fit(dataset_train[feature_names], dataset_train['return'] > 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神經網路Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "dataset_scaled = ss.fit_transform(dataset)\n",
    "dataset_scaled = pd.DataFrame(dataset_scaled, columns=dataset.columns, index=dataset.index)\n",
    "dataset_scaled['return'] = dataset['return']\n",
    "dataset_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "n = 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "indexes = []\n",
    "dataset_scaled_x = dataset_scaled[feature_names]\n",
    "\n",
    "for i in tqdm.tqdm_notebook(range(0, len(dataset_scaled)-n)):\n",
    "    X.append(dataset_scaled_x.iloc[i:i+n].values)\n",
    "    y.append(dataset_scaled['return'].iloc[i+n-1])\n",
    "    indexes.append(dataset_scaled.index[i+n-1])\n",
    "#dataset_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.array(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神經網路 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "#model.add(keras.layers.Dense(100, activation=\"relu\", input_shape=(len(feature_names),)))\n",
    "model.add(layers.LSTM(100, return_sequences=True, input_shape=X[0].shape))\n",
    "model.add(layers.LSTM(100))\n",
    "model.add(layers.Dense(8))\n",
    "model.add(layers.Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "\n",
    "adam = keras.optimizers.Adam(0.0006)\n",
    "\n",
    "model.compile(optimizer=adam, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神經網路訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_scaled_train = dataset_scaled[:'2015']\n",
    "\n",
    "import datetime\n",
    "X_train = X[indexes < datetime.datetime(2016, 1, 1)]\n",
    "y_train = y[indexes < datetime.datetime(2016, 1, 1)]\n",
    "\n",
    "checkpoint_filepath = './checkpoint_u22'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train > 1,\n",
    "    batch_size=5000,\n",
    "    epochs=300,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ey = model.predict(X)\n",
    "ey = pd.Series(ey.swapaxes(0,1)[0], index=indexes)\n",
    "ey.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = twii[indexes]\n",
    "returns = (eq.shift(-1) - eq)\n",
    "\n",
    "signal = (ey > ey.quantile(0.6)).rolling(10).sum() > 0\n",
    "signal = signal.shift(1).fillna(False)\n",
    "\n",
    "eq = (returns[signal]['2016':]).cumsum()\n",
    "eq.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(signal.astype(int).diff().abs().fillna(0) * 3)['2016':].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
